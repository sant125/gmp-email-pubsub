# Arquitetura

## VisÃ£o geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚  â”‚  Pod 1   â”‚  â”‚  Pod 2   â”‚                                â”‚
â”‚  â”‚          â”‚  â”‚          â”‚                                â”‚
â”‚  â”‚ /metrics â”‚  â”‚ /metrics â”‚                                â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚       â”‚             â”‚                                       â”‚
â”‚       â”‚             â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                                â”‚
â”‚  â”‚  Prometheus Agent/      â”‚                                â”‚
â”‚  â”‚  GMP Collector          â”‚                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚           â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Managed Prometheus      â”‚
â”‚   (AMP / GMP)             â”‚
â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  TSDB Storage       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Rules Engine       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  AlertManager       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  SMTP / SNS    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         ğŸ“§ Email
```

## Componentes

### 1. Application Pods

Seus apps rodando no Kubernetes. Precisam expor mÃ©tricas no formato Prometheus:

```
GET http://pod-ip:port/metrics

# Retorna algo tipo:
http_requests_total{method="GET"} 1523
up{job="sample-app"} 1
container_memory_working_set_bytes 134217728
```

Qualquer app pode expor mÃ©tricas. Tem bibliotecas client pra todas as linguagens:
- Go: `prometheus/client_golang`
- Python: `prometheus_client`
- Java: `io.prometheus.simpleclient`
- Node.js: `prom-client`

### 2. Prometheus Collector/Agent

**GCP (GMP Collector):**
- Roda como pods no namespace `gmp-system`
- Service discovery automÃ¡tico via `PodMonitoring` CRD
- Faz scraping dos pods e envia pro backend GMP
- VocÃª nÃ£o gerencia esses pods

**AWS (Prometheus Agent):**
- VocÃª instala via Helm no cluster
- Configurado pra fazer remote write pro AMP
- Service discovery via `ServiceMonitor` CRD (Prometheus Operator)
- VocÃª gerencia o deployment

O papel deles Ã©:
1. Descobrir quais pods coletar
2. Scraping periÃ³dico (default: 30s)
3. Enviar mÃ©tricas pro serviÃ§o gerenciado

### 3. Managed Prometheus (TSDB)

**GCP (Google Managed Prometheus):**
- Backend totalmente gerenciado
- Storage ilimitado (vocÃª paga por uso)
- 50GB/mÃªs grÃ¡tis
- MÃ©tricas ficam no Cloud Monitoring
- Query via Metrics Explorer ou API

**AWS (Amazon Managed Prometheus):**
- Backend totalmente gerenciado
- Storage pago por GB-mÃªs
- 10M mÃ©tricas grÃ¡tis no free tier (primeiro ano)
- Query via grafana ou API compatÃ­vel com Prometheus

Ambos armazenam as mÃ©tricas em Time Series Database (TSDB), otimizado pra dados de sÃ©ries temporais.

### 4. Rules Engine

Avalia as regras de alerta periodicamente:

```yaml
- alert: PodDown
  expr: up{job="sample-app"} == 0
  for: 1m
  labels:
    severity: critical
```

A cada intervalo (ex: 30s):
1. Roda a query `up{job="sample-app"} == 0`
2. Se der true, alerta vira PENDING
3. Se continuar true por 1min (`for`), vira FIRING
4. Notifica o AlertManager

O `for` evita alertas por ruÃ­do temporÃ¡rio (pod reiniciando, health check momentÃ¢neo, etc).

### 5. AlertManager

Recebe alertas do Rules Engine e decide o que fazer:

**Agrupamento (grouping):**
```yaml
route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 5m
```
Se 10 pods caÃ­rem em 10s, agrupa num alerta sÃ³.

**Roteamento:**
```yaml
routes:
- match:
    severity: critical
  receiver: pagerduty
- match:
    severity: warning
  receiver: email
```
Alertas critical vÃ£o pro PagerDuty, warning pro email.

**Silenciamento:**
Durante deploy, vocÃª pode silenciar alertas temporariamente.

**Retry:**
Se o envio falhar, tenta de novo.

**GCP:** AlertManager gerenciado (vocÃª nÃ£o vÃª pod dele)

**AWS:** VocÃª pode usar o AlertManager integrado do AMP ou instalar um no cluster.

### 6. Notification Channels

**GCP (SMTP direto):**
```yaml
receivers:
- name: email
  email_configs:
  - to: 'voce@email.com'
    smarthost: 'smtp.gmail.com:587'
    auth_username: 'seu@gmail.com'
    auth_password: 'app-password'
```

AlertManager conecta direto no SMTP e envia email.

**AWS (SNS):**
```yaml
receivers:
- name: sns
  sns_configs:
  - topic_arn: 'arn:aws:sns:...'
```

AlertManager publica no SNS, que distribui pra email/SMS/Lambda/etc.

## Fluxo completo de um alerta

```
T+0s    â”‚ Pod crash
        â”‚ MÃ©trica up vira 0
        â”‚
T+0s    â”‚ Collector scrape
        â”‚ Detecta up=0
        â”‚ Envia pro Managed Prometheus
        â”‚
T+30s   â”‚ Rules Engine avalia
        â”‚ Query: up{job="sample-app"} == 0
        â”‚ Resultado: true
        â”‚ Alerta â†’ PENDING
        â”‚
T+60s   â”‚ Rules Engine avalia de novo
        â”‚ Ainda true hÃ¡ 1min
        â”‚ Alerta â†’ FIRING
        â”‚
T+61s   â”‚ AlertManager recebe
        â”‚ Inicia group_wait (10s)
        â”‚ Aguarda outros alertas pra agrupar
        â”‚
T+71s   â”‚ AlertManager processa
        â”‚ Agrupa alertas similares
        â”‚ Aplica template de email
        â”‚ Envia via SMTP/SNS
        â”‚
T+72s   â”‚ Gmail/SNS recebe
        â”‚ Processa e entrega
        â”‚
T+75s   â”‚ ğŸ“§ Email chega
```

Tempo total: ~75 segundos desde o pod cair.

Se o pod voltar antes de 1min, o alerta nunca dispara (fica sÃ³ em PENDING).

## Namespaces no GCP (GMP)

**gmp-system:**
- Onde o GMP coloca os pods gerenciados
- `collector`: scraper
- `rule-evaluator`: avalia regras
- `frontend`: API de query
- VocÃª NÃƒO edita nada aqui

**gmp-public:**
- Onde VOCÃŠ coloca as configs
- `OperatorConfig`: config global
- `Rules`: regras de alerta
- `Secret` (alertmanager-config): config do AlertManager
- Rules SÃ“ funcionam se estiverem nesse namespace

**default (ou outro):**
- Onde seus apps rodam
- `PodMonitoring`: pode ficar aqui, junto com o app
- `Deployment`, `Service`, etc

Hierarquia:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    gmp-system       â”‚ â† Pods gerenciados (read-only pra vocÃª)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    gmp-public       â”‚ â† Suas configs (Rules, AlertManager)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    default          â”‚ â† Seus apps + PodMonitoring
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## SeguranÃ§a e IAM

**GCP (Workload Identity):**
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-app
  annotations:
    iam.gke.io/gcp-service-account: my-app@project.iam.gserviceaccount.com
```

O pod usa a ServiceAccount K8s que mapeia pra ServiceAccount GCP. Consegue acessar recursos do GCP sem passar credenciais.

**AWS (IRSA - IAM Roles for Service Accounts):**
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-app
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::123456789:role/my-app-role
```

O pod assume a IAM Role via OIDC. Consegue acessar recursos AWS (S3, SNS, etc) sem credenciais hardcoded.

## Anatomia de uma mÃ©trica

```
metric_name{label1="value1", label2="value2"} valor timestamp
```

Exemplo real:
```
http_requests_total{method="GET", path="/api/users", status="200"} 1523 1698765432
```

**metric_name:** O que vocÃª tÃ¡ medindo

**labels:** DimensÃµes (pra filtrar, agrupar, etc)

**valor:** O nÃºmero

**timestamp:** Quando foi coletado (opcional, Prometheus adiciona se nÃ£o tiver)

### Tipos de mÃ©tricas

**Counter:** SÃ³ aumenta (ou reseta a 0)
- `http_requests_total`
- `errors_total`
- Use `rate()` pra calcular taxa

**Gauge:** Sobe e desce
- `memory_usage_bytes`
- `active_connections`
- Use direto

**Histogram:** Distribui valores em buckets
- `http_request_duration_seconds`
- Usa `histogram_quantile()` pra calcular percentis

**Summary:** Como histogram, mas calcula quantis no cliente
- Raramente usado (histogram Ã© melhor)

## PromQL: exemplos prÃ¡ticos

**Quantos pods tÃ£o up?**
```promql
up{job="sample-app"}
```

**Taxa de requisiÃ§Ãµes por segundo (Ãºltimos 5min):**
```promql
rate(http_requests_total[5m])
```

**Uso de memÃ³ria em %:**
```promql
(container_memory_working_set_bytes / container_spec_memory_limit_bytes) * 100
```

**P95 de latÃªncia:**
```promql
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
```

**Pods com uso de memÃ³ria > 80%:**
```promql
(container_memory_working_set_bytes / container_spec_memory_limit_bytes) > 0.8
```

## Custos: breakdown

**GCP:**
- GKE Autopilot: ~$50-70/mÃªs (depende do uso real)
- GKE Standard: ~$123/mÃªs (nodes + control plane)
- GMP: $0 (atÃ© 50GB/mÃªs)
- SMTP: $0 (Gmail grÃ¡tis)
- **Total:** ~$50-123/mÃªs

**AWS:**
- EKS: ~$73/mÃªs (control plane) + nodes
- Nodes (2x t3.medium): ~$60/mÃªs
- AMP: $0 no free tier, depois ~$2/mÃªs
- SNS: ~$0.50/mÃªs (email) ou ~$5/mÃªs (SMS)
- **Total:** ~$133-145/mÃªs

A parte de observabilidade em si Ã© barata. O caro Ã© o cluster.

## Managed vs Self-Hosted

**Managed:**
- PrÃ³s: Zero manutenÃ§Ã£o, escala automÃ¡tico, alta disponibilidade inclusa
- Contras: Custo, vendor lock-in, menos controle

**Self-Hosted:**
- PrÃ³s: Controle total, mais barato (se vocÃª jÃ¡ tem cluster)
- Contras: VocÃª gerencia storage, escala, backup, HA, updates

Pra lab/aprendizado, managed Ã© mais fÃ¡cil.

Pra produÃ§Ã£o pequena (<1M mÃ©tricas), self-hosted pode valer a pena.

Pra produÃ§Ã£o grande (>10M mÃ©tricas), managed compensa.

## LimitaÃ§Ãµes

**GCP (GMP):**
- Amarrado ao GKE (nÃ£o funciona fora)
- NÃ£o dÃ¡ pra acessar AlertManager direto (sÃ³ via config)
- Query via console Ã© menos flexÃ­vel que Grafana

**AWS (AMP):**
- Precisa configurar remote write (mais complexo)
- Custo sobe rÃ¡pido com muitas mÃ©tricas
- Free tier sÃ³ no primeiro ano

## ReferÃªncias

- Prometheus docs: https://prometheus.io/docs/
- PromQL cheatsheet: https://promlabs.com/promql-cheat-sheet/
- GMP docs: https://cloud.google.com/stackdriver/docs/managed-prometheus
- AMP docs: https://docs.aws.amazon.com/prometheus/
- Awesome Prometheus Alerts: https://samber.github.io/awesome-prometheus-alerts/
